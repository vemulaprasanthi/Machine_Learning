{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuM82NIsoe0gi/YmItn6FV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vemulaprasanthi/Machine_Learning/blob/main/Exp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akgEP8LIXa6C",
        "outputId": "797794b3-c442-49fe-b051-797d8a2956ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Sky Temperature Humidity    Wind Water Forecast EnjoySport\n",
            "0  Sunny        Warm   Normal  Strong  Warm     Same        Yes\n",
            "1  Sunny        Warm     High  Strong  Warm     Same        Yes\n",
            "2  Rainy        Cold     High  Strong  Warm   Change         No\n",
            "3  Sunny        Warm     High  Strong  Cool   Change        Yes\n",
            "[['Sunny' 'Warm' 'Normal' 'Strong' 'Warm' 'Same']\n",
            " ['Sunny' 'Warm' 'High' 'Strong' 'Warm' 'Same']\n",
            " ['Rainy' 'Cold' 'High' 'Strong' 'Warm' 'Change']\n",
            " ['Sunny' 'Warm' 'High' 'Strong' 'Cool' 'Change']]\n",
            "['Yes' 'Yes' 'No' 'Yes']\n",
            "\n",
            "Initialization of specific_h and general_h\n",
            "['Sunny' 'Warm' 'Normal' 'Strong' 'Warm' 'Same']\n",
            "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
            "\n",
            "Steps of Candidate Elimination Algorithm 1\n",
            "['Sunny' 'Warm' 'Normal' 'Strong' 'Warm' 'Same']\n",
            "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
            "\n",
            "Steps of Candidate Elimination Algorithm 2\n",
            "['Sunny' 'Warm' '?' 'Strong' 'Warm' 'Same']\n",
            "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
            "\n",
            "Steps of Candidate Elimination Algorithm 3\n",
            "['Sunny' 'Warm' '?' 'Strong' 'Warm' 'Same']\n",
            "[['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', 'Same']]\n",
            "\n",
            "Steps of Candidate Elimination Algorithm 4\n",
            "['Sunny' 'Warm' '?' 'Strong' '?' '?']\n",
            "[['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
            "\n",
            "Final Specific_h:\n",
            "['Sunny' 'Warm' '?' 'Strong' '?' '?']\n",
            "\n",
            "Final General_h:\n",
            "[['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?']]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/training_data.csv')\n",
        "print(data)\n",
        "\n",
        "# Extract concepts (features) and target (labels)\n",
        "concepts = np.array(data.iloc[:, 0:-1])  # Extract all columns except the last one (features)\n",
        "print(concepts)\n",
        "target = np.array(data.iloc[:, -1])  # Extract the last column (target values)\n",
        "print(target)\n",
        "\n",
        "def learn(concepts, target):\n",
        "    \"\"\"\n",
        "    learn() function implements the learning method of the Candidate Elimination\n",
        "    algorithm.\n",
        "    Arguments:\n",
        "    concepts - a data frame with all the features\n",
        "    target - a data frame with corresponding output values\n",
        "    \"\"\"\n",
        "    # Initialize specific_h and general_h\n",
        "    specific_h = concepts[0].copy()  # Initialize specific_h as the first concept (most specific)\n",
        "    print(\"\\nInitialization of specific_h and general_h\")\n",
        "    print(specific_h)\n",
        "\n",
        "    # Initialize general_h as the most general hypothesis (all '?' representing any value)\n",
        "    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]\n",
        "    print(general_h)\n",
        "\n",
        "    # Learning iterations\n",
        "    for i, h in enumerate(concepts):\n",
        "        if target[i] == \"Yes\":  # If the target is \"Yes\" (positive example)\n",
        "            for x in range(len(specific_h)):\n",
        "                if h[x] != specific_h[x]:  # Generalize specific_h if it doesn't match the current example\n",
        "                    specific_h[x] = \"?\"  # Replace with '?' to generalize\n",
        "                    general_h[x][x] = \"?\"  # Also update the general_h to generalize\n",
        "\n",
        "        elif target[i] == \"No\":  # If the target is \"No\" (negative example)\n",
        "            for x in range(len(specific_h)):\n",
        "                if h[x] != specific_h[x]:\n",
        "                    general_h[x][x] = specific_h[x]  # Fix the general boundary to exclude this example\n",
        "                else:\n",
        "                    general_h[x][x] = \"?\"  # Replace with '?' to generalize\n",
        "\n",
        "        print(f\"\\nSteps of Candidate Elimination Algorithm {i + 1}\")\n",
        "        print(specific_h)\n",
        "        print(general_h)\n",
        "\n",
        "    # Clean up general_h by removing redundant all '?' rows\n",
        "    indices = [i for i, val in enumerate(general_h) if val == [\"?\", \"?\", \"?\", \"?\", \"?\", \"?\"]]  # Adjust size as needed\n",
        "    for i in sorted(indices, reverse=True):  # Remove from the end to avoid index shift\n",
        "        general_h.pop(i)\n",
        "\n",
        "    # Return final specific_h and general_h\n",
        "    return specific_h, general_h\n",
        "\n",
        "\n",
        "# Run the learning process\n",
        "s_final, g_final = learn(concepts, target)\n",
        "\n",
        "# Output the final hypotheses\n",
        "print(\"\\nFinal Specific_h:\", s_final, sep=\"\\n\")\n",
        "print(\"\\nFinal General_h:\", g_final, sep=\"\\n\")\n"
      ]
    }
  ]
}